%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%  Fundamentals  %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Fundamentals} \label{Ch:Fundamentals}
In this chapter, the foundations of the thesis are explained. Starting with the principles behind MRI acquisition, acceleration and reconstruction as well as image registration and deep learning fundamentals.

\section{Magnetic Resonance Imaging} \label{Sec:MRI}
MRI is a non-invasive, radiation-free, tomographic imaging technology based on measurements of a magnetic field.  An MRI machine comprises four main components, as seen in Figure~\ref{fig:MRISchematic}. The first component is a strong magnet powerful enough to generate a static magnetic field $B_0$ that is required to induce nuclear proton polarization. The second is a radio frequency (RF) system which generates an alternating magnetic field $B_1$ at the resonant frequency $f$ and detects the MR signal that is returned from the patient. The third component is the set of gradient systems (oriented orthogonally in X, Y and Z directions) that generates linear magnetic field variations, which are then superimposed upon $B_0$ and are used to spatially encode the MR signal. In clinical MR scanners, the three gradient sets and whole-body RF coils are typically concentrically positioned inside the bore of the magnet. The fourth component is a computer providing the user interface, generating images to be displayed on the console~\cite{Serai2021}.

\begin{figure}[h] %tpb
 	\centering
 	\includegraphics[width=\linewidth]{./Images/MRI-Schematic.png} 
 	\caption{Schematic of an MRI scanner taken from~\cite{Serai2021}.}
 	\label{fig:MRISchematic}
 \end{figure} 

\subsection{Magnetic Excitation and Relaxation} \label{SubSec:MagneticExcitationAndRelaxation}
%In the following section, the basic principles underlying MR imaging are presented. These include the relation between RF excitation and relaxation.
The base principles behind MR imaging are RF excitation and relaxation. Through these, the raw k-space data is measured which enables the reconstruction to an image. Terminology such as $\text{T}_1$ and $\text{T}_2$ relaxation times are introduced and explained. These are the basis for the pulse sequences discussed in section~\ref{SubSec:ImageAcquisitionAndK-Space}.

\subsubsection{Radio Frequency Excitation}
Individual nuclei precess around the field $B_0$ at a
resonance frequency called the Larmor frequency $\omega_0$ of the net magnetization vector, which occurs in the RF range of the electromagnetic spectrum and is related to the external magnetic field as:
\begin{equation} \label{eq:LarmorFrequency}
	\omega_0 = \gamma \cdot B_0,
\end{equation}
with $\gamma$ being the gyromagnetic ratio, which is a fixed value depending on the nuclei~\cite{SamplingStrategies}. When nuclei are placed in the presence of a strong static magnetic field such as $B_0$, they split into two energy states, either aligned parallel to $B_0$ (spin-up state) or anti-parallel to $B_0$ (spin-down state). The spin-up state has a slightly lower energy level as compared to the spin-down state and is therefore preferred. This slight difference in the spin states ($0.001\%$) results in an overall net magnetization $M$ aligned in the same direction as $B_0$~\cite{Serai2021}. To create an MR signal, the spins are excited out of their resting equilibrium, tipping $M$ away from $B_0$. To detect the signal from the hydrogen nuclei in the tissues an additional external field $B_1$ is introduced at the resonant Larmor frequency $\omega_0$ that can affect magnetization vector, causing it to rotate into a plane orthogonal to its original orientation. The rotated vector continues to precess around the $B_0$. The precession of the magnetization vector in the transverse plane can be detected by an RF coil tuned to $\omega_0$. RF coils can be operated in a receive-only mode, in which case the inherent body coil is used as a transmitter; or the RF coils can be both transmit and receive. The purpose of the RF transmit coil is to create a time-varying $B_1$ field at right angles to $B_0$ that could be linearly or circularly polarized. The closer the receiving coil is to the source of the MR signal, the better the signal-to-noise ratio (SNR). Receiver coils generally comprise arrays of smaller individual coils or elements; however, each individual coil element has a limited depth penetration~\cite{Serai2021}. Multiple arrays of coils, termed phased-array coils, can be used together to achieve a higher coverage. 
%These are electronically decoupled from one another so that they do not appear as just a single large coil. 
The images from individual coils are independently reconstructed and then grouped together to create the final image. An RF pulse of amplitude $B_1$, called excitation pulse, is applied for a certain time duration to tip the magnetization at an angle away from the $B_0$ field. This induces a voltage in the receiver RF coil; this induced voltage is known as the free induction decay (FID). After the pulse, the magnetization returns to thermal equilibrium by processes known as MR relaxation. To fully encode the spatial information within the field of view (FOV), pulse sequences must be iterated numerous times. The time between successive iterations of a pulse sequence is known as the repetition time (TR). The time between the application of the initial RF pulse and the middle of the detected echo is called echo time (TE). Due to this the overall time to acquire an MR image is quite long~\cite{Serai2021}.\\

\subsubsection{Magnetic Relaxation}
Once the RF pulse is turned off, $M$ continues to precess as it returns to its thermal equilibrium state. During this time, two types of relaxation occur: $\text{T}_1$ (longitudinal) and $\text{T}_2$ (transverse). The tissue sensitivity of $\text{T}_1$ and $\text{T}_2$ is very valuable as this tissue dependence gives MR its excellent soft-tissue contrast~\cite{Serai2021}. $\text{T}_1$ relaxation describes the recovery of the longitudinal magnetization back to thermal equilibrium following a perturbation by an RF pulse. The longitudinal component regrows along the Z direction with a time constant $\text{T}_1$. 
%In other words, after the RF pulse is turned off, the protons that were disturbed give their energy to the surrounding environment and return back to their original equilibrium state, realigning with $B_0$. 
Hence, $\text{T}_1$ relaxation is also called longitudinal relaxation. 
%Furthermore, because $\text{T}_1$ relaxation involves the loss of energy that was put into the spin system by the RF pulse, it is also referred to as spin-lattice relaxation, the lattice consisting of surrounding macromolecules. This loss of energy is stimulated by the fluctuating magnetic fields associated with the dipoleâ€“dipole interactions of neighboring magnetic moments. 
$\text{T}_1$ relaxation can only occur when magnetic field fluctuations occur at the resonant frequency $\omega_0$. The rate at which the spin magnetization $M_z$ recovers to $M_0$ at time $t$ is called $\text{T}_1$ relaxation time~\cite{Serai2021}. It can be expressed as follows:
\begin{equation}
	M_z = M_0 \cdot \bigg(1 - e^{-\frac{t}{\text{T}_1}} \bigg).
\end{equation}
A preferred method of measuring $\text{T}_1$ relaxation is the Look-Locker method, which is based on the principle that one does not need to wait for the net magnetization vector to equilibrate in order to measure $\text{T}_1$. Instead, an RF pulse is used with a small flip, which can be repeatedly applied. The acquisition pulse sequence is designed to generate a train of signals that gradually approaches a steady-state recovery~\cite{Serai2021}. 

\subsubsection{Cine CMR Imaging}
Cardiac cine MRI is the gold standard for the assessment of cardiac morphology and function~\cite{KuestnerCINE,Kramer2020}. To capture a motion-free image of the heart requires the image to be acquired in just a few tens of milliseconds. This means both limiting the number of phase encoding steps, and thus spatial resolution, as well as making the TR as short as possible~\cite{CineReview1,CineReview2}. Whilst this can be done, it is at the cost of significantly reducing the image quality. To achieve acceptable image quality, the image acquisition times would become too long to effectively freeze heart motion in the image. For routine cardiovascular magnetic resonance (CMR) therefore, the MR signals are acquired over multiple heart beats, synchronizing the pulse sequence in the cardiac cycle~\cite{Lin2022}. Cardiac synchronization is achieved by using the electrocardiogram (ECG) signal of the patient. The R wave is detect and used to generate a synchronization pulse for the data acquisition~\cite{Lanzer1985}. This enables images of the beating heart to be obtained either at a single time point (still imaging) or at multiple time points through the cardiac cycle (cine imaging)~\cite{CineReview1}. A schematic of this process can be seen in Figure~\ref{fig:CineWorkFlow}.

\begin{figure}[h] %tpb
	\centering
	\includegraphics[width=\linewidth]{./Images/CineWorkFlow.pdf} 
	\caption{Synchronization of imaging pulse sequences via ECG, taken from~\cite{CineReview1}. The R wave is detected in the ECG, which is then used to align the pulse sequences for imaging.}
	\label{fig:CineWorkFlow}
\end{figure}

\noindent Conventional imaging techniques need several minutes to generate a full image, which leads to degradation by respiratory motion~\cite{CineReview1}. This can be reduced by e.g. respiratory compensation methods (respiratory gating), cardiac synchronized fast imaging techniques combined with patient breath-holds (BHs) or ultra-fast imaging techniques. Patient BHs combined with fast imaging techniques are most common in practice~\cite{CineReview1}. This technique requires multiple patient BHs during data acquisition, which can be difficult for very sick or sedated patients, further complicating the work-flow and extending exam time~\cite{Lin2022}. Additionally, free-breathing cine imaging is essential and significant in specific conditions such as exercise-stressed CMR exams~\cite{Chew2020}. Therefore, free-breathing CMR with good image quality and comparable spatio-temporal resolution to traditional BH CMR is clinically desirable~\cite{Wang2021}. 
%for expanded CMR application, improved exam work-flow, and patient tolerance. Real-time (RT) cine imaging, which suppresses potential respiratory motion artifacts by acquiring each cardiac phase in one shot, allows shorter BH times or fully free-breathing acquisition but sacrifices spatio-temporal resolution~\cite{Lin2022}.

\subsection{Image Acquisition and the Concept of k-Space} \label{SubSec:ImageAcquisitionAndK-Space}
After discussing the physical mechanisms behind MRI, it is time to look at the actual process of acquiring the image as well as the concept of the k-space. The image contrast in MR imaging arises from tissues generating MR signals with different intensities due to their physical properties. Contrast weighting of the MR signal is obtained by the design of pulse sequences, which consist of repetitive trains of RF pulses. Two of the most common pulse sequences are gradient echo and spin echo sequences. 

\subsubsection{Gradient Echo Sequence}
In a gradient echo (GE) sequence, the FID signal is manipulated by a bi-polar gradient. The excitation pulse tilts the magnetization by $\alpha$ degrees. For $\alpha = 90\degree$, the longitudinal magnetization is rotated in the transverse plane. The data is sampled during a GE at the echo time (TE) after the excitation pulse. This GE is achieved by dephasing the spins with a negative gradient before they are rephased by an opposite gradient with opposite polarity to generate an echo. An overview of the process can be seen in Figure~\ref{fig:GradientEcho}. 

\begin{figure}[h] %tpb
	\centering
	\includegraphics[width=\linewidth]{./Images/GradientEcho.pdf} 
	\caption{Schematic of an GE sequence taken from~\cite{PulseSequences}. The FID signal is manipulated by a bi-polar gradient to create a GE. The excitation RF pulse tilts the magnetization by $90 \degree$ and the signal is sampled during a GE at time TE which is caused by a bi-polar gradient.}
	\label{fig:GradientEcho}
\end{figure}

\subsubsection{Spin Echo Sequence}
With a spin echo (SE) sequence, pure $\text{T}_2$-weighted contrast can be generated. When a $90\degree$ pulse rotates the magnetization into the transverse plane, the resulting FID signal quickly decays due to the strong $\text{T}^*_2$ dephasing, which is the $T_2$ decay shortened by extra phase dispersion~\cite{Serai2021}. If after a time $\frac{\text{TE}}{2}$ a $180\degree$ pulse is applied, the spins will be flipped and start to rephase. After another time, $\frac{\text{TE}}{2}$, a measurable echo signal is created. The spin dephasing due to static magnetic field inhomogeneities is compensated by inverting the spins with the $180\degree$ refocusing pulse. This process is visualized in Figure~\ref{fig:SpinEcho}.
%\\Consequently, the decay of the signal at time TE will solely originate from the $\text{T}_2$ relaxation. A SE sequence can also be used to generate proton density or $\text{T}_1$-weighted signals by using a short TE and a long or short TR, respectively~\cite{PulseSequences}.

\begin{figure}[h] %tpb
	\centering
	\includegraphics[width=\linewidth]{./Images/SpinEcho.pdf} 
	\caption{Schematic of an SE sequence taken from~\cite{PulseSequences}. A $90 \degree$ pulse rotates the magnetization resulting in a quickly decaying FID signal. At $\frac{\text{TE}}{2}$ the spins are flipped by applying a $180 \degree$ pulse and give rise to a SE at time TE after waiting another $\frac{\text{TE}}{2}$ following the $180 \degree$ pulse.}
	\label{fig:SpinEcho}
\end{figure}


\subsubsection{Introduction to k-Space}
The concept of the k-space generalizes the relation of a time-variant signal to a spectrum. A 2D image is related to a 2D k-space data set by a 2D FT, as seen in Figure~\ref{fig:2D_MRI_Measurement}. As the FT is a information-preserving operation, the k-space data contains exactly the same information as the image data. Thus, in order to get the full image information, the full k-space data must be measured. The task of imaging is converted to the task of finding a way to measure the necessary corresponding k-space data. Using the Larmor frequency from Equation~\ref{eq:LarmorFrequency} the coordinates in 2D k-space will thus be given as $k_x = \gamma \cdot G_x \cdot t$ and $k_y = \gamma \cdot G_y \cdot t$~\cite{SamplingStrategies}. 

\begin{figure}[H] %tpb
	\centering
	\includegraphics[width=\linewidth]{./Images/2D_MRI_Measurement.png} 
	\caption{Correspondence of the image domain and the k-space via a 2D FT, adapted from~\cite{SamplingStrategies}. Consequently, a 2D iFT can be used to go from image space into k-space. In practice, a 2D FFT and iFFT are used due to faster computation. The coordinates of each domain are defined by the Larmor frequency according to Equation~\ref{eq:LarmorFrequency}.}
	\label{fig:2D_MRI_Measurement}
\end{figure}

\noindent In order to acquire an MR image, methods need to be developed to traverse the k-space. There are only two possibilities, as seen in Figure~\ref{fig:kSpaceTrajectories}. First, applying a gradient to create a line defined by the orientation of the gradient (see Figure~\ref{fig:constant_k-space_gradient}). 
%As long as the gradient is kept constant, the k-space trajectory will be a straight line. 
Second, applying a refocusing pulse leading to a jump around the origin (see Figure~\ref{fig:refocusing_k-sapce_pulse}). It is clear that the latter alone cannot cover the whole k-space, since the trajectory would only jump between the two mirror symmetric points. A combination of refocusing pulses and gradients needs to be used. All existing k-space imaging techniques are based on some combination of these two means of traversing the k-space~\cite{SamplingStrategies}. 

\begin{figure}[h] %tpb
	\centering
	\begin{subfigure}{0.445\textwidth}
    		\includegraphics[width=\textwidth]{./Images/ConstantGradient.pdf}
    		\caption{Schematic of a constant gradient creating a straight k-space trajectory.}
    		\label{fig:constant_k-space_gradient}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.445\textwidth}
    		\includegraphics[width=\textwidth]{./Images/RefocusingPulse.pdf}
    		\caption{Schematic of an refocusing pulse inverting the phase of the k-space.}
    		\label{fig:refocusing_k-sapce_pulse}
	\end{subfigure}
	\caption{Methods of moving in the k-space using a) constant gradients to move along straight lines or b) mirror the k-space at the origin using a refocusing pulse. Adapted from~\cite{SamplingStrategies}.}
	\label{fig:kSpaceTrajectories}
\end{figure}

\noindent Is should be noted that the signals are measured at discrete time intervals called the dwell-time of data acquisition. This discrete sampling leads to an ambiguous assignment of frequencies above a given threshold which is called the Nyquist frequency~\cite{SamplingStrategies}. The Nyquist frequency therefore determines the acquisition bandwidth inside which the signal should occur. The definition of the k-space coordinates implies that these are invariant with respect to the actual strength of the gradient used, as long as $G$ and $t$ are constant. Mathematically, data acquisition under a strong gradient and in a shorter acquisition time will yield the same k-space data and thus the same image as acquisition under a weaker gradient and a longer acquisition time. A shorter acquisition time and a closer spacing of sampling points are equivalent to a higher-acquisition bandwidth. Since the received noise grows with the square root of the bandwidth, a faster imaging technique will therefore by principle always carry the penalty of a lower SNR. For a conventional SE imaging sequence a typical acquisition time of 5 to 10~ms for each phase-encoding step is used. Acquisition of 192 to 256 phase-encoding steps therefore requires a total net acquisition time of 1 to 2~s. However, this is much shorter than the actual acquisition time of such a sequence, which is determined by the TR of the $\text{T}_1$ contrast. It follows that the SNR of a fast imaging sequence leading to acquisition times of approximately 50~ms, will be lowered by at least a factor of 5 to 10, regardless of the actual sequence used~\cite{SamplingStrategies}.\\
Different parts of the k-space encode different features of the image. The center of the k-space hold the lower frequencies which represent the image contrast, whereas the outer parts encode the higher frequencies for sharp structures. Due to the symmetry of the 2D FT, this statement can also be reversed. The image center will be encoded by low-resolution k-space data. Therefore, sampling of sparsely distributed k-space data will reduce the effective FOV of the final image~\cite{AdvancesPI,SamplingStrategies}. Mathematically, the final image will look exactly the same, irrespective of the way the data is sampled in the k-space. In practice, however, different approaches can have a major impact on image quality as the data has to sampled sequentially. The observed spins evolve not only as a function of the gradients defining the intended k-space trajectory, but are also influenced by other mechanisms unrelated to image encoding. It is noteworthy that the coordinates in k-space are expressed in units of a phase angle across space. Any mechanism affecting the phase of the signal along this trajectory will therefore alter the k-space trajectory. Some such commonly occurring mechanisms are flow and motion effects, magnetic field inhomogeneities, as well as susceptibility and chemical shift effects. The consequence of such phase effects in terms of imaging properties is dependent on the particular sequence and data sampling speed. In addition to phase effects, the signal decay with $\text{T}_2$ needs to be taken into account also, especially if the data acquisition time is similar or even longer than the $\text{T}_2$ of the observed tissues under construction~\cite{SamplingStrategies}.


\subsubsection{Rectilinear K-Space Sampling}
Almost all MR imaging sequences use rectilinear k-space sampling, meaning the points are sampled in a rectangular grid. This 
is also referred to as Cartesian sampling and allows the usage of the fast Fourier transform (FFT) enabling image reconstruction in a very short time (under 1~s). For comparison, using the 2D FT to transform a non-rectilinear grid can take about 5 to 50~min per image~\cite{SamplingStrategies}. During acquisition, one or more lines of k-space parallel to a Cartesian axis are collected following application of an RF pulse and generation of an RF echo. Adjacent points in a single line are collected in rapid succession in a single echo. The time between echoes and adjacent lines is much slower. The direction of fast acquisition is known as the frequency direction and the other one or two directions are known as the phase-encode directions. Following line-by-line filling of k-space in a Cartesian sequence, each layer of a filled grid is subsequently used to reconstruct a single image slice~\cite{Bardo2021}.


\subsubsection{Non-Rectilinear K-Space Sampling}
A problem of rectilinear sampling techniques is the heterogeneous nature of the k-space trajectories used. 
%Data is acquired along straight k-space lines under a constant gradient. 
Going around the corner of the trajectory requires very fast switching for a brief period, which is demanding on the gradient power amplifiers.
%, which have to be able to alternate between the two modes. 
A more even load is offered by the use of curved k-space trajectories. Especially spiral trajectories~\cite{SpiralMRI, SpiralMRI2} have won considerable interest due to their very efficient use of the gradient system. A practical problem relates to image reconstruction which requires algorithms that can take several seconds per image on a typical scanner~\cite{SamplingStrategies}. 
%The ultimate success of spiral imaging will then be determined by its inherent imaging properties, which are significantly different from rectilinear scans. 
Constant off-resonance effects, such as chemical shift, field inhomogeneity, and susceptibility, will not lead to a displacement in the phase-encoding direction, but to blurring of the corresponding structures~\cite{SamplingStrategies}. A problem of spiral imaging is the fact that severe artifacts can arise when the k-space trajectory produced by the gradient system is not exactly identical to the trajectory used for image reconstruction. It is thus necessary to accurately calibrate the gradient system or to even measure the actual trajectory used. A favorable property of spirals is the motion correction inherent to the trajectory~\cite{SpiralMRI3}. Apart from spirals, other non-rectilinear k-space trajectories have been suggested~\cite{NonRectlinear1,NonRectlinear2}. Back projection uses a star-like trajectory and allows the realization of extremely short echo times. Its inhomogeneous k-space coverage with a high sampling density for points at the center of k-space and its somewhat awkward artifact behavior have limited its success for conventional imaging~\cite{SamplingStrategies}. %Other trajectories, such as rosettes or even random k-space trajectories, have also been explored. 
A common feature of all non-rectilinear trajectories relates to their non-periodic nature, which produces severe artifacts when the FOV of the data acquisition is less than the size of the object. For rectilinear scans this leads to fold-over artifact, which can sometimes be tolerated. For non-rectilinear scans, an insufficient FOV of the k-space data, misregistration artifacts can be very severe. 
%Spirals produce a circular rim artifact around the image. 
It is therefore mandatory to ensure that the k-space trajectory is sufficiently dense to always cover the whole object of interest~\cite{SamplingStrategies}. 

\subsection{Imaging Acceleration and Reconstruction} \label{SubSec:ImagingAccelerationReconstruction}
To alleviate the slow image acquisition times of the MR imaging, different acceleration techniques have been proposed. These cause strong image artifacts when using a simple iFT for reconstruction. As a consequence more sophisticated approaches for image reconstruction have been developed.

\subsubsection{Image Acceleration via k-Space Subsampling} \label{SubSubSec:AccelerationSubsampling}
Most acceleration techniques included scanning less k-space lines during signal acquisition, omitting certain frequencies by zero-padding. This is because total acquisition time $\text{T}_{Ac}$ for the 2D case is determined by two factors:
\begin{equation}
	\text{T}_{Ac} = \text{TR} \cdot \text{N}_{PE},
\end{equation}
where $\text{N}_{PE}$ is the number of phase encoding lines. The TR determines the contrast in the image while $\text{N}_{PE}$ determines the resolution~\cite{ParallelMRI}. To reduce the acquisition time, either the k-space data must be collected more quickly (reducing TR) or the amount of collected k-space data must be decreased (reducing $\text{N}_{PE}$). The speed at which k-space data can be collected is determined by the desired image contrast and the strength of the magnetic field gradients needed to encode the k-space data~\cite{ParallelMRI}. For some sequences like SE, the TR must be left long in order to generate the desired contrast. For others, it is possible to reduce the TR while still maintaining image contrast. However, in these cases the electrical power required to run the magnetic field gradients faster would be massive~\cite{ParallelMRI}. There is also a physiological limit, as rapidly switching high-strength magnetic field gradients on and off can induce electrical currents in the patient, potentially causing peripheral nerve stimulation~\cite{Cohen1990,Ham1997}. In addition, hardware limitations also restrict the TR, like maximum gradient amplitude and slew rate~\cite{AdvancesPI}. \\
Instead of shortening TR, the number of k-space lines can be reduced. The amount of lines that are left out and zero-filled is usually given by a reduction factor $R$, defined as the ratio between the number of k-space points in the fully-sampled data compared to the subsampled data~\cite{AdvancesPI,ParallelMRI}. While there are different subsampling techniques, most involve fully sampling the center region containing the lower frequencies and dropping higher frequencies. These are deemed less important as they contain mostly details and fine image structures, whereas the low frequencies encode the general image structure and contrast~\cite{SamplingStrategies}. All of these methods create artifacts during image reconstruction as seen in Figure~\ref{fig:ExamplesSubsampling}. The more lines are missing/zeroed, the more intense these artifacts become. In order to still reconstruct images with as few artifacts as possible, different reconstruction algorithms have been developed such as parallel imaging and compressed sensing, which are discussed in the following sections.

\begin{figure}[h] %tpb
	\centering
	\graphicspath{{images/}{\main/images/}}
	\includegraphics[width=\linewidth]{ExamplesSubsampling.png} 
	\caption{Examples of different subsampled k-space trajectories (top row) and their associated aliasing artifacts in image space (bottom row) taken from~\cite{AdvancesPI}. Omitted/zeroed data is represented by dashed lines.}
	\label{fig:ExamplesSubsampling}
\end{figure}

\noindent Recently, using neural network to find better k-space subsampling patterns has been proposed. These try to learn new subsampling strategies in a data-driven manner like pruning unimportant k-space frequencies~\cite{MRISubsamplingPruning} as well as deep learning based radial~\cite{DeepMRIReconstructionRadialSubsampling} and other non-Cartesian~\cite{DeepMRIReconstructionSubsampling} subsampling for MRI acceleration. These promise better image quality and easier reconstruction for the same amount of deleted k-space data. However, they have yet to be used in a clinical application~\cite{MRISubsamplingPruning}.


\subsubsection{Parallel Imaging}
Parallel imaging (PI) is a robust method for accelerating the acquisition of MRI data by subsampling the k-space data while still being able to reconstruct high quality images using an array of receiver coils. One of several PI algorithms can then be used to reconstruct artifact-free images from either the aliased images (SENSE-type reconstruction) or from the subsampled k-space data (GRAPPA-type reconstruction)~\cite{AdvancesPI}. PI requires special hardware known as phased array coils that contain multiple independent receiver channels. Each coil element is most sensitive to the magnetization closest to it and less sensitive to magnetization further away. Individually, each coil has high local SNR but inhomogeneous coverage. To expand the FOV while maintaining high SNR, several coils are organized in an array. The images from each channel are usually combined into a single image with relatively homogeneous intensity by taking a root sum-of-squares (RSS) combination~\cite{DeepMRIReconstructionSubsampling}. Theoretically, the maximum acceleration factor is limited by the number of coils, thus, for PI to be successful, each coil must have a unique sensitivity variation along the direction that is accelerated. For example, an array with four coils arranged in a line may be able to attain a maximum R = 4 along one direction, but no acceleration would be possible in the perpendicular direction~\cite{AdvancesPI}.\\
As mentioned before, PI techniques fall into one of two classes, depending on whether aliased pixels are separated in the image domain (SENSE) or missing phase encoding lines are reconstructed in k-space (GRAPPA). Sensitivity encoding (SENSE)~\cite{SENSE1} is a PI technique which unfolds superimposed pixels in the image domain. For Cartesian k-space sampling with a uniform acceleration factor of R = 3 and a receiver array with four coils the undersampling reduces the FOV threefold, such that three pixels from the fully-sampled image fold onto the same pixel in the aliased image~\cite{AdvancesPI}. SENSE uses prior knowledge of the coil sensitivity profiles to separate folded pixels and recover the full FOV image. If the acceleration factor exceeds the number of coils, then the SENSE algorithm will not be able to recover an un-aliased image~\cite{ParallelMRI}. In practice, the largest achievable acceleration factor is usually smaller than the theoretical limit because of coil sensitivity overlap and coil not being orthogonal~\cite{AdvancesPI}.\\
One common feature of PI is the amplification of noise in the reconstructed image, though with varying degrees:
\begin{equation} \label{eq:SNR-SENSE}
	\text{SNR}_{\text{SENSE}}(x,y) = \frac{\text{SNR}_{\text{full}}(x,y)}{\sqrt{R} \cdot g(x,y)},
\end{equation}
where the geometry factor $g(x,y)$ describes the spatial pattern of noise enhancement, $\text{SNR}_{\text{SENSE}}(x,y)$ the SNR in the reconstructed SENSE image and $\text{SNR}_{\text{full}}(x,y)$ the SNR of the fully sampled image~\cite{AdvancesPI}. In addition to the $g$-factor losses, which depend on variables like number of coils, array configuration, etc., the SNR decreases with the square root of $R$, which is known as Fourier averaging~\cite{AdvancesPI}.\\
While SENSE unfolds aliased signals in the image domain, generalized partially parallel acquisitions (GRAPPA)~\cite{GRAPPA} synthesizes missing data points directly in k-space~\cite{ParallelMRI}. There, the use of inhomogeneous receiver coils effectively spreads information from one k-space point to nearby k-space points. GRAPPA exploits these k-space redundancies across coils to reconstruct missing k-space data using neighboring acquired points. A single missing k-space data point (target point) is synthesized as a linear combination of acquired neighboring k-space points (source points) with the spatial arrangement of source and target points being called GRAPPA kernel~\cite{ParallelMRI}. Each acquired source point is multiplied by a coefficient (GRAPPA weight) and the results are added to estimate the target point. A single target point for one coil is reconstructed using source points from all other coils. For Cartesian sampling, the weights are shift invariant to a first approximation, so the same GRAPPA weights can be applied throughout k-space. The reconstruction can be described as convolving or sliding the GRAPPA kernel throughout the k-space~\cite{AdvancesPI}. While SENSE uses additional information in the form of coil sensitivity profiles to unfold aliased pixels, GRAPPA requires extra data to estimate the weights. This is called autocalibrating because several additional phase encoding lines, called the auto-calibration signal (ACS), are collected near the k-space origin for calculating the weights~\cite{ParallelMRI}. These lines can be used as a reference for calibration as the center is usually fully sampled. The SNR of images reconstructed using GRAPPA is also reduced according to Equation~\ref{eq:SNR-SENSE}, however, because GRAPPA does not require an explicit estimate of the coil sensitivities, it tends to be more robust than SENSE to inconsistencies between the calibration and subsampled data~\cite{AdvancesPI}.\\
SENSE and GRAPPA can be combined in what is called iterative self-consistent parallel imaging (SPIRiT)~\cite{SPIRiT}. Like GRAPPA k-space kernels are used to recover missing information by exploiting correlations between neighboring k-space points, though the reconstruction is framed as an inverse problem similar to SENSE. 
%Regardless of the original sampling trajectory, SPIRiT outputs a Cartesian k-space. 
The reconstruction is typically initialized with the subsampled zero-filled k-space and is solved iteratively. The algorithm minimizes and balances the errors of two terms: calibration consistency and data consistency~\cite{AdvancesPI}. The first is calculated using a so-called SPIRiT kernel in the k-space similar to GRAPPA, while the second term enforces consistency with the subsampled data as the difference between the reconstructed data and acquired data should be zero at the originally sampled positions. Thus reconstruction should only recover missing k-space points without changing the known data points~\cite{AdvancesPI}. ESPIRiT~\cite{ESPIRiT} is an extension of SPIRiT that uses k-space kernel operations to derive a set of eigenvector maps that behave like coil sensitivities, which can be incorporated in a generalized SENSE reconstruction. This requires calibration data from the fully sampled region at the center of k-space. Unlike SENSE and GRAPPA, SPIRiT and ESPIRiT reconstruct images iteratively and can require long computation times which can be addressed by using e.g. parallelized GPUs~\cite{AdvancesPI}.

\subsubsection{Compressed Sensing}
The idea behind compressed sensing (CS) is that sparse or compressible signals can be acquired in an efficient way by applying compression already in the data acquisition process. According to CS theory, sparse or compressible signals can be recovered from fewer samples than required by the Shannon-Nyquist sampling theorem~\cite{CS-MRI}. This is achieved by applying an appropriate sampling scheme and reconstruction that employs signal sparsity to recover the signal. MRI fulfills two important requirements for the application of CS: medical imaging is naturally compressible by sparse coding and MRI scanners acquire samples of the encoded image in spatial frequency, rather than direct pixel values. CS emerged as an abstract mathematical idea that if one measures a relatively small number of random linear combinations of the signal values the signal can be reconstructed with good accuracy from these few measurements by a non-linear procedure due to the underlying signal being compressible. In MRI, the sampled linear combinations are the individual Fourier coefficients (k-space samples) and CS is able to make accurate reconstructions from a small subset of k-space, rather than an entire k-space grid~\cite{CS-MRI}. It should be noted that unlike PI approaches, the k-space is incoherently sampled; thus, noise-like artefacts appear in the image when a direct iFT is performed. To remove the artefacts caused by the undersampling, iterative reconstruction is used. Different sparsifying transforms can be used for CS like the commonly utilized wavelet transform or total variation, which enforces the sparsity of the image gradients. The advantages of total variation include its simplicity, rotation invariance, and capability of preserving edges and providing good image quality~\cite{PulseSequences}. There are also several methods combining CS and PI trying to achieve higher acceleration factors~\cite{PI+CS, PI+CS2}.

\subsection{Motion-Compensated Image Reconstruction} \label{SubSec:Motion-CompensatedReconstruction}
Patient motion during acquisition is one of the major impediments of high-quality MRI scans. This is especially true for thoracic and abdominal imaging, as organs move during breathing. Such motion artifacts can be compensated either during or after reconstruction using image registration.


\subsubsection{Motion in MRI Acquisition} \label{SubSubSec:IntraviewandInterviewMotion}
Due to the long acquisition times, motion is one of the major extrinsic factors influencing MR image quality. Patient and physiological motion induces aliasing along the phase-encoding direction and blurring of the image content~\cite{Kuestner2022}.
%, where the appearance depends on the imaging trajectory.
%This motion can induce several consequences on MR signal formation.
Intraview and interview motion have to be distinguished between. Motion is intraview when occurring during individual MR experiments (between RF excitation and echo formation), whereas motion is interview when occurring between individual MR experiments. Whenever the period of motion is slow compared to the period of MR acquisition 
%defined by the repetition time 
TR, the assumption can be made that motion is interview. This is often reasonable when considering pseudo-periodic motion induced by respiration, and also possibly by cardiac contraction, which are the two common sources of motion in cardiac and abdominal imaging (adult respiratory period is about 4 to 5~s, TR $\approx 10$~ms for fast imaging)~\cite{GRICS}. Interview motion results in spatial encoding inconsistencies, and thus in image deterioration which can take complex forms like blurring or ghosting artifacts. Several strategies can be employed to handle patient motion better with patient cooperation being the most commonly used~\cite{GRICS}. However, BHs cannot last much longer than 20~s with physiological drifts being inevitable. This leads to a limitation on the time for signal recording and thus SNR. Moreover, the position of organs in successive BHs may not be reproducible. Synchronization techniques are well-established and systematically used in clinical protocols, but they require a high-level of motion reproducibility. This is often a limiting factor considering heart rate variability (whether in free breathing or during a BH), and respiratory variability in terms of amplitude and frequency~\cite{GRICS}. 

\subsubsection{Motion-Compensated Reconstruction} \label{SubSubSec:ReconstructionPipelines}
Motion-resolved data acquisition is usually accelerated by PI or CS techniques yielding subsampled k-space data. In order to reconstruct aliasing-free images, these methods rely on reconstruction schemes that incorporate sparsity or low-rank constraints to solve the ill-posed problem~\cite{CS-MRI,ParallelMRI,LowRank+SparseMRI}. Fixed sparsity assumptions in CS are often too restrictive and incapable of fully modeling spatio-temporal dynamics~\cite{Kuestner2022}. After reconstruction, non-linear motion fields can be estimated in image space from reconstructed images by solving a registration problem. A particular interest and challenge lies in the derivation of reliable motion fields which capture the spatio-temporal non-linear transformations, such as respiratory or cardiac movement. Instead of performing these two steps sequentially, motion-compensated image reconstruction schemes like \emph{GRICS}~\cite{GRICS} integrate both motion field estimation and motion modeling into the reconstruction process. These two parts of the motion-compensated reconstruction pipeline can be performed by either conventional iterative algorithms like in GRICS or neural networks~\cite{Kuestner2022}. These methods require reliable motion-resolved images from which the motion fields can be estimated. Motion field estimation can be controlled or supported by external motion surrogate signals~\cite{CorderoGrande2016}, initial motion field estimates~\cite{Atkinson1997,Batchelor2005}, from motion-aliased images~\cite{Haskell2019} or low-frequency image contents~\cite{Usman2020}. Moreover, spatio-temporal redundancies can be exploited to achieve an aliasing-free image. While these methods have been proven to be more robust against registration errors, they can require a significantly increased computational demand and/or limit imaging acceleration~\cite{Kuestner2022}. 


\section{Image Transformations and Registration} \label{Sec:ImageTransformationsAndRegistration}
In this chapter, a brief overview over different kinds of image transformations is given, followed by an introduction into the challenges of image registration. The goal of image registration is to compute a transformation that aligns two images - moving and fixed. This transformation is then applied to the moving image to create an warped image that more closely resembles the fixed image. But first, the different kinds of image transformations must be discussed.

\subsection{Image Transformations} \label{SubSec:ImageTransformations}
In medical image registration, there are three basic transformation types that are typically used: rigid, affine and non-linear (deformable)~\cite{Strittmatter2023}. All of these are modeled in different ways.

\subsubsection{Rigid Transformations}
Rigid transformations are linear and global transformations that affect the whole image. As these are global operations, one can express them as matrix and vector operations. A rigid transformation includes translation and rotation and can be represented by:
\begin{equation}
	\mathbf{T}_{rigid} (x) = \mathbf{R} \cdot \overrightarrow{p} + \overrightarrow{t},
\end{equation}
with $\mathbf{R}$ being the rotation matrix, $\overrightarrow{p}$ a point in the image and $\overrightarrow{t}$ the translation vector.  For 3D images, the rotation matrix and the translation vector require three parameters each. Thus, six parameters have to be calculated for a rigid transformation for 3D images~\cite{Strittmatter2023}.

\subsubsection{Affine Transformations}
Affine transformations are also linear and global transformations, however they include translation, rotation, scaling and shearing. Matrix multiplication can be used to merge all of these individual transformations into a single matrix:
\begin{align}
	\overrightarrow{p}' 	&= \mathbf{R} \cdot \mathbf{S} \cdot \mathbf{t} \cdot  \overrightarrow{p}	\\
	&= 
	\begin{bmatrix}
		\cos(\theta) & -\sin(\theta) & 0\\
		\sin(\theta) & \cos(\theta) & 0\\
		0 & 0 & 1
	\end{bmatrix}
	\cdot 
	\begin{bmatrix}
		s & 0 & 0\\
		0 & s & 0\\
		0 & 0 & 1
	\end{bmatrix}
	\cdot 
	\begin{bmatrix}
		1 & 0 & t_x\\
		0 & 1 & t_y\\
		0 & 0 & 1
	\end{bmatrix}
	\cdot
	\begin{bmatrix}
		x\\
		y\\
		1
	\end{bmatrix}
	\\
	&=
	\begin{bmatrix}
		s \cdot \cos(\theta) & -s \cdot \sin(\theta) & t_x\\
		s \cdot \sin(\theta) & s \cdot \cos(\theta) & t_y\\
		0 & 0 & 1
	\end{bmatrix}
	\cdot
	\begin{bmatrix}
		x\\
		y\\
		1
	\end{bmatrix} =
	\begin{bmatrix}
		x'\\
		y'\\
		1
	\end{bmatrix} ,
\end{align}
with $\theta$ being the angle of the rotation for the rotation matrix $\mathbf{R}$, $s$ the scaling factor for the scaling matrix $\mathbf{S}$ as well as $t_x$ and $t_y$ being the translations in x- and y-direction. This can be further generalized as a single matrix multiplication:
\begin{equation}
	\overrightarrow{p}' = \mathbf{T}_{affine} \cdot  \overrightarrow{p} = 
	\begin{bmatrix}
		a_{11} & a_{12} & a_{13}\\
		a_{21} & a_{22} & a_{23}\\
		0 & 0 & 1
	\end{bmatrix}
	\cdot
	\begin{bmatrix}
		x\\
		y\\
		1
	\end{bmatrix}
	 = 
	 \begin{bmatrix}
		x'\\
		y'\\
		1
	\end{bmatrix},
\end{equation}
with $\mathbf{T}_{affine}$ being the general affine transformation matrix~\cite{Strittmatter2023}.

\subsubsection{Non-Linear Transformations}
Non-linear or deformable transformations are used to model local deformations in images that rigid and affine transformations cannot capture as these transformations are not capable of locally warping the image. Non-linear transformations include radial basis functions, physical continuum models, and large deformation models like diffeomorphisms. These transformations are complex and do not preserve straightness or parallelism:
\begin{equation}
	\mathbf{T}_{deformable} (x) = x + \phi (x),
\end{equation}
with $\phi$ being the deformation or displacement field. Deformable image registration is an ill-posed problem, often requiring regularization to ensure a smooth and plausible displacement field~\cite{Strittmatter2023}.

\subsection{Image Registration} \label{SubSec:ImageRegistration}
Image registration is a challenging, yet important task for image processing. It remains one of the main research topics and challenges in the field of image analysis~\cite{Chen2023}. The task consists of transforming a moving image to match a fixed image~\cite{NiftiReg}. In the medical field this can be used for clinical applications such as disease diagnosis and monitoring, image-guided treatment delivery, and post-operative assessment~\cite{Chen2023}. Medical image registration is typically used to pre-process data for tasks like object detection and segmentation. Thus, the performance of these methods is dependent on the quality of image registration~\cite{Chen2020}. This was historically done manually by medical professionals, however, the quality of manual alignments are very dependent on the expertise of the clinicians~\cite{Haskins2020}. These manual registrations are thus not only time consuming, but also hardly reproducible leading to high interobserver-variability. While the need for automatic registration is very much apparent, the computational cost of traditional registration algorithms often prohibited their usage. With the rise of deep learning, neural networks now provide an fast alternative to conventional algorithms and manual registration~\cite{Haskins2020}. However, it should be noted that these networks still need a lot of data and computational power to be trained.\\
In pair-wise image registration, two images, called moving ($M$) and fixed ($F$), are aligned with a spatial transformation T. As discussed in section~\ref{SubSec:ImageTransformations}, there are three types of transformations: rigid, affine, and non-linear (deformable). While the latter is the most difficult to compute, these are also the ones most common in clinical practice~\cite{Zou2022}. Additionally, deformable image registration can be utilized for computer-assisted interventions like biopsy~\cite{Tam2016} and (MRI-guided) radiotherapy~\cite{Chen2017, Rigaud2019}. Registration can be described as an optimization problem:
\begin{equation}
	\text{T}' = \underset{\text{T}}{\text{argmax}} \, S(F, \text{T}(M)),
\end{equation}
where $\text{T}'$ is the best transformation maximizing the similarity $S$ between the two images. This can be done iteratively, continuously improving the estimates for the desired T, maximizing the similarity~\cite{Chen2020}. Deformable image registration is an ill-posed problem, making it fundamentally different from other computer vision tasks such as object localization, segmentation or classification~\cite{Fu2020}. Given two images, deformable image registration aims to find a spatial transformation that warps the moving image to match the fixed image as closely as possible. However, there is no ground-truth available and without enforcing any constraints on the properties of the spatial transformation, the resulting cost function is ill-conditioned and highly non-convex~\cite{Chen2020}. In order to address the latter and ensure tractability, all image registration algorithms regularize the estimated displacement, based on some prior assumptions on the properties of the underlying unknown deformation~\cite{Chen2020}. While there are many registration algorithms proven to work, they lack computation speed, which can be alleviated by new deep learning approaches~\cite{Fu2020}.


\section{Deep Learning} \label{Sec:DeepLearning}
Deep learning, and neural networks in general, have seen a significant rise in usage over the last couple of years due to many breakthroughs in areas of image recognition~\cite{Xu2023}, segmentation~\cite{U-Net} and also registration~\cite{Voxelmorph}. After discussing different network architectures, specific use-cases for image registration are discussed and a brief overview of network training and testing, including evaluation metrics, is given.

\subsection{Deep Learning Architectures} \label{SubSec:DeepLearningArchitectures}
Neural networks, despite their theoretical foundations being around for decades, have seen a drastic rise in popularity over the last few years as constraints on computational power and data size have been alleviated~\cite{Chen2020}. Especially deep neural networks have become more popular and are often summarized under the term deep learning. In recent years the development and use of deep neural networks has grown substantially, sustained by rapid improvements in computational hardware like GPUs~\cite{Chen2023}. Consequently, clinical applications requiring image classification, segmentation, registration, or object detection/localization, have witnessed significant improvements in algorithmic performance, in terms of accuracy and/or efficiency~\cite{Chen2020}. The following network architectures are widely used for different tasks including medical image registration.

\subsubsection{Convolutional Neural Networks} \label{SubSubSec:CNNs}
Convolutional neural networks (CNNs) are a type of neural networks with regularized multi-layer perceptrons, which are mainly used for image processing~\cite{Xiao2021}. CNNs use convolution operations instead of general matrix multiplications in typical neural networks~\cite{CNN1,CNN2}. These convolutional filters make CNNs very suitable for visual signal processing. Because of their excellent feature extraction capabilities in combination with further operations, CNNs are some of the most successful architectures for image analysis. Different variants have been proposed achieving state-of-art performances for various image processing tasks~\cite{CNN2}. A typical CNN usually consists of multiple convolutional layers, max pooling layers, batch normalization layers, optional dropout layers, a sigmoid or softmax layer. In each convolutional layer, multiple channels of feature maps are extracted by sliding trainable convolutional kernels across the input feature maps. Hierarchical features with high-level abstraction are extracted using multiple convolutional layers. These feature maps are passed through multiple fully connected layer before reaching the final decision layer. Max pooling is often used to reduce the image size and promote spatial invariance~\cite{Chen2020}. Batch normalization is used to reduce internal covariate shift among the training samples. Weight regularization and dropout layers are used to prevent data overfitting~\cite{Fu2020}. The loss is often defined as the difference between predicted and target output. CNNs are usually trained by minimizing this loss via gradient back propagation using optimization methods like Adam~\cite{Adam}. 

\subsubsection{U-Net} \label{SubSubSec:U-Net}
The U-Net architecture~\cite{U-Net} is a CNN variant first used for image segmentation, but has been proven to also be effective for image registration tasks~\cite{Jia2022b}. It adopts symmetrical contractive and expansive paths with skip connections between them. The encoding blocks extract important features from the image using convolution layers and max pooling, which are then stored in a latent space between the paths. From there the image is reconstructed using upsampling and (de-)convolutions in the decoding blocks. Additionally, skip connections are used to improve the spatial resolution~\cite{U-Net}. The U-Net enables effective feature learning from a small number of training data~\cite{Fu2020}. 

\subsubsection{Autoencoders} \label{SubSubSec:Autoencoders}
An autoencoder (AE) is a CNN that learns to reconstruct an image from its input without supervision. AEs usually consists of an encoder which extracts the input features, which are stored in a low-dimensional latent space, similar to a U-Net, and a decoder which restore the original input from the latent space. To prevent an AE from learning an identity function, regularized autoencoders were invented, which can be used for e.g. denoising AEs. Variational AEs (VAEs) are generative models that learn latent representation using a variational approach, which constrains the variability of the outputs. VAEs can been used for anomaly detection and image generation~\cite{Fu2020}.


\subsection{Deep Learning for Image Registration} \label{SubSec:DLImageRegistration}
Recently, there has been a surge in the use of deep learning based approaches for medical image registration~\cite{Chen2023}. Their success is largely due to their ability to perform fast inference, and the flexibility to leverage auxiliary information such as anatomical masks as part of the training process~\cite{Fu2020}. The most effective methods, such as \emph{VoxelMorph}~\cite{Voxelmorph}, typically employ a U-Net architecture to estimate dense spatial deformation fields. These methods require only one forward pass during inference, making them orders of magnitude faster than traditional iterative methods~\cite{Fu2020}. Following the success of \emph{VoxelMorph}, numerous deep neural networks have been proposed for various registration tasks~\cite{Fourier-Net+}. Other approaches also utilize e.g. CNNs and AEs~\cite{Chen2023}. 

\subsubsection{Supervised Registration} \label{SubSubSec:SupervisedRegistration}
Supervised registration describes training a network with a ground truth displacement field that is either real (created by a medical professional) or synthetic (generated via registration algorithms). Thus, the loss can easily be calculated as the difference in the displacements of the network prediction and ground truth (see Figure~\ref{fig:SupervisedRegistration}). These methods have achieved notable results with real displacement fields as supervision~\cite{Zou2022}. However, this approach is limited by the size and diversity of the dataset. As the displacements are often calculated by conventional algorithms their effectiveness might be limited for difficult problems with which the traditional algorithms struggle. Fully supervised methods are widely studied and have notable results, but the generation of real or synthetic displacement fields is hard, and these displacements fields might be different from the real ground truth, which can impact the accuracy and efficiency of these kinds of methods~\cite{Zou2022}. Notable approaches include \emph{BIRNet}~\cite{BIRNet} and \emph{LAPNet}~\cite{LAPNet} with the latter working in the k-space domain.

\begin{figure}[h] %tpb
	\centering
	\graphicspath{{images/}{\main/images/}}
	\includegraphics[width=\linewidth]{SupervisedRegistrationGraph.jpg} 
	\caption{Schematic of the training process for a supervised network calculating the loss directly to a ground truth displacement, taken from~\cite{Zou2022}.}
	\label{fig:SupervisedRegistration}
\end{figure}


\subsubsection{Unsupervised Registration} \label{SubSubSec:UnsupervisedRegistration}
As the preparation of ground truth displacements for supervised methods is difficult and time consuming, limitations in generalizing results for various domains and registration tasks are inevitable~\cite{Chen2023}. Thus, unsupervised registration has a more convenient training process with paired images as inputs, but without a ground truth to compare against. Typically, the loss function computes the similarity between the aligned images (see Figure~\ref{fig:UnsupervisedRegistration}) as well as the smoothness of the displacement field, rather than the difference to a ground truth~\cite{Zou2022}. Example are the \emph{IC-Net}~\cite{IC-Net},  \emph{VoxelMorph}~\cite{Voxelmorph}, \emph{TransMorph}~\cite{TransMorph} and \emph{SYMNet}~\cite{SYM-Net}.

\begin{figure}[h] %tpb
	\centering
	\graphicspath{{images/}{\main/images/}}
	\includegraphics[width=\linewidth]{UnsupervisedRegistrationGraph.jpg} 
	\caption{Schematic of the training process for an unsupervised network with only a image similarity loss (no ground truth), taken from~\cite{Zou2022}.}
	\label{fig:UnsupervisedRegistration}
\end{figure}


\subsection{Network Training and Testing} \label{SubSec:NetworkTrainingAndTesting}
In order to train any neural network, a large amount of data is needed. This data can be videos, images, audio, text, etc. The data is usually divided into three subsets: the training, validation and test subset. 

\subsubsection{Training and Back-Propagation}
The first subset is used for the training of the network. It is often the largest subset and should include a lot of variance for the network to learn well. Neural networks in general learn by adapting their weights to perform better at a specific task on a specific dataset/domain. This is done in a process called back-propagation, where the loss calculated between a target and the current output of the model. This is acquired by a simple forward pass through the network, and the desired output is propagated backwards through the model and the weights are optimized using e.g. gradient decent~\cite{CNN2}. The second subset is also used during training, but is not learned as no back-propagation is performed. This is done to validate the networks training progress and to prevent overfitting, which is a common problem especially for larger networks. This occurs when a network learns every example from the training set, but no general properties as intended. To prevent this, the unseen validation data can be repeatedly used, as it is not learned, to see whether the network improves on new data. Once it has been trained for a long time and the validation performance stagnates, or drops, the training is stopped. This is known as early stopping and is a very common strategy to prevent overfitting while optimizing training time~\cite{CNN1}.

\subsubsection{Testing and Evaluation Metrics} \label{SubSubSec:TestingEvalutionMetrics}
The last subset is the test set, which is used for the final evaluation of the network. It can be used for evaluating performance, as well as memory consumption and inference time. This set cannot be used for training and needs to be completely new to the network. For datasets with a lot of patients, a single patient should be withheld in order to truly test on unseen data. \\
Different metrics can be used for evaluation of a networks registration performance including metrics computed on the images and on the generated displacements. The MSE is calculated between a fixed (ground truth) image and the warped image giving a pixel-wise comparison:
\begin{equation}
	\text{MSE} = \frac{1}{N} \sum_{i=1}^{N} |F(x,y) - W(x,y)|^2,
\end{equation}
where $F$ is the fixed image and $W$ is the warped image with $N$ being the number of pixels in the images. The lower the MSE the higher the similarity with 0 being a perfect match (the images are exactly the same). The MSE can also be used to calculate the peak SNR (PSNR)~\cite{Ghoul2024}, which describes the ratio between the maximum possible power of a signal and the power of corrupting noise. It is defined as:
\begin{equation}
	\text{PSNR} = 20 \cdot \log_{10} \bigg(\frac{2^B - 1}{\sqrt{\text{MSE}}} \bigg),
\end{equation}
with $B$ being the bit depth of the image and the metric being defined in decibel (dB) due to the logarithmic scale. Another common image metric is the structural similarity index measure (SSIM)~\cite{SSIM}, which ranges from 1 (complete similarity) to 0 (no similarity). It tries to evaluate the general similarity instead of a pixel-wise comparison like the MSE, making it more robust against contrast changes:
\begin{equation}
	\text{SSIM} = \frac{(2 \mu_F \mu_W + c_1) \cdot (2 \sigma_{FW} + c_2)}{(\mu_F^2 + \mu_W^2 + c_1) \cdot (\sigma_F^2 + \sigma_W^2 + c_2) },
\end{equation}
with $\mu_F, \mu_W$ being the mean values of the images $F$ and $W$; $\sigma_F^2, \sigma_W^2$ the variances of $F$ and $W$ as well as $\sigma_{FW}$ the covariance for $F$ and $W$, with $c_1, c_2$ being constants derived from the dynamic range of the images. For comparison of segmentations the Dice score~\cite{Xiao2021} is a commonly used metric to estimate the similarity of two segmentations. A score of 1 indicates a complete overlap/match and a score of 0 indicates no overlapping of the segmentations. It is calculated as follows:
\begin{equation}
	\text{Dice} = \frac{2 |M_F \cap M_W|}{|M_F| + |M_W|},
\end{equation}
with $M_F$ and $M_W$ being segmentations corresponding to $F$ and $W$. $M_W$ is obtained by warping the manual segmentation $M_F$ using the generated displacement~\cite{NiftiReg}. Aside from image similarity and the evaluation of segmentations, the displacement itself can be evaluated. This is based on the assumption that the displacement should be smooth as folding could result in unrealistic anatomic structures, thus indicating errors. Jacobian matrices are the derivatives of the displacement field $\phi$ that form a second order tensor field:
\begin{equation}
	J_{\phi}(p) = \nabla \mathbb{\phi} (p) = \begin{pmatrix}
	\frac{\partial \phi_1(p)}{\partial x_1} & \frac{\partial \phi_1(p)}{\partial x_2} & \frac{\partial \phi_1(p)}{\partial x_3} \\
	\frac{\partial \phi_2(p)}{\partial x_1} & \frac{\partial \phi_2(p)}{\partial x_2} & \frac{\partial \phi_2(p)}{\partial x_3} \\
	\frac{\partial \phi_3(p)}{\partial x_1} & \frac{\partial \phi_3(p)}{\partial x_2} & \frac{\partial \phi_3(p)}{\partial x_3} 
	\end{pmatrix},
\end{equation}
encoding the local stretching, shearing and rotating of the displacement field for a point $p$. The determinants of such matrices, also called Jacobian determinants $|J_{\phi}|$, must be positive everywhere to avoid folding as a region of negative determinants would indicate that the one-to-one mapping has been lost~\cite{DARTEL}. Thus the percentage of non-positive Jacobian determinants of the deformation $\% \, |J_{\phi}|\leq0$ can be used to evaluate the quality of the generated displacement field~\cite{Chen2023}.
