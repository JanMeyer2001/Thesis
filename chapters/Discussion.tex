%%%%%%%%%%%%%%%%%%%%%%%
%%%%%  Discussion %%%%%
%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Discussion} \label{Ch:Discussion}
After presenting the results of the experiments described in section~\ref{Sec:Experiments}, it is time to discuss the implications of the results. First, the parameter tests conducted on the \emph{ACDC} dataset and then the evaluation of the reconstruction pipeline on the \emph{CMRxRecon} dataset.

\section{Parameter Tests on the ACDC Dataset} \label{Sec:DiscussionParameterTestsACDC}
For the first tests, the performance of \emph{Fourier-Net}, \emph{Fourier-Net+} and \emph{4xFourier-Net+} was evaluated on the \emph{ACDC} dataset alongside different parameter tests and ablation studies. These results now need to be analyzed and interpreted.

\subsection{Fourier-Net versus Fourier-Net+} \label{SubSec:DiscussionFourier-NetvsFourier-Net+ACDC}
In a first comparative study, the performance of \emph{Fourier-Net}, \emph{Fourier-Net+} and \emph{4xFourier-Net+} was compared in section ~\ref{SubSec:ResultsFourier-NetvsFourier-Net+ACDC} together with their respective memory consumption.\\
For the dense displacement variants, the diffeomorphic transform increases the performance slightly for \emph{Fourier-Net} and \emph{4xFourier-Net}, but decreases for \emph{Fourier-Net+}. The times between the baseline and diffeomorphic versions are comparable.
The results for the band-limited versions are very similar with \emph{Fourier-Net} and \emph{Fourier-Net+} performing slightly worse  with the diffeomorphism, while \emph{4xFourier-Net} performs better.  These changes are not consistent with the dense displacement versions, however, the band-limited \emph{4xFourier-Net} version might be an outlier, as all of the other models are not affected as much by the diffeomorphic transform. The percentage of non-positive Jabobian determinants decreases for all diffeomorphic variants, which is as expected.\\
Overall, the dense displacement versions perform better in terms of Dice (with and without the background label), SSIM and MSE for all models. This is to be expected as the dense displacement versions can use all of the available k-space data for the registration task, while the band-limited versions have only a limited amount of k-space data, directly impacting and limiting their performance. The dense displacement are only slightly better in the SSIM and MSE metrics, however the difference is not quite as large as with the Dice scores. As the differences between the frames is not quite as large, the weaker registration performance does not impact this metric as much as the Dice score, which is focused on the moving cardiac region.\\
Only in terms of the percentage of non-positive Jabobian determinants does the band-limited displacement actually perform better as the band-limiting probably allows for only a smaller deformation. However, the difference is still very small, especially for the diffeomorhpic versions, and it could be argued that a better registration performance at the cost of some image folding is an acceptable trade-off. \\
In terms of inference time the dense displacement variants are surprisingly slightly faster despite having a larger encoder, however all of the model are in the low milliseconds ($<40$~ms). Lastly, the memory consumption needs to be addressed. The dense displacment variants have a larger encoder as discussed before and thus have a lot more parameters, especially for the more optimized \emph{Fourier-Net+} and \emph{4xFourier-Net} (about 5 times more). The number of Mult-Adds and the amount of total memory are more than doubled (almost tripled for \emph{4xFourier-Net}) for the dense displacement versions compared to those with a band-limited displacement across all models. This shows that a larger network produces better results, however for certain applications where efficiency is needed a smaller, but slightly worse, network might be more beneficial.


\subsection{Starting Channel Size} \label{SubSec:DiscussionStartingChannelsACDC}
One of the most important parameters for the networks is the channel size. A larger channel size means more features, but also a larger network. The results from section~\ref{SubSec:ResultsStartingChannelsACDC} show that memory efficiency and registration performance for \emph{Fourier-Net+} and \emph{4xFourier-Net+} cannot be optimized at the same time. There is a trade-off between the two. As the channel sizes increase, making the network larger, the performance also increases. While this effect is quite large at the beginning, it plateaus rather quickly. This trade-off and the diminishing returns imply that there is a sweet spot where the network is still efficient while maintaining a good performance. The starting channel size 16 was thus chosen for the following experiments.

\subsection{Fourier-Transform Crop Size} \label{SubSec:DiscussionFTCropSize}
The FT crop is specific to \emph{Fourier-Net+} and \emph{4xFourier-Net+}, however, the size of the crop has a mayor impact on the input images as a smaller crop leads to more compressed images, but also better memory usage. Similarly to channel size before, the results in section~\ref{SubSec:ResultsFTCropSize} indicate that there is no sweet-spot to be found that maximizes both memory efficiency and registration performance. The latter decreases drastically with a smaller crop size. This is to be expected as the smaller FT drop compresses the images more  making an accurate registration harder. Interestingly, the percentage of non-positive Jabobian determinants actually decreases for smaller crop sizes, perhaps because the displacements on the compressed images are not as extreme and thus more smooth. Inference time also seems to decrease slightly with a smaller crop, although the time measurements are not quite consistent.\\
The number of parameters does not change for different crop sizes as the networks themselves do not change, however the number of Mult-Adds and the total memory still change with the image size. Both decrease with a larger crop size as the image gets smaller. This effect is again not linear as a reduction in image size yields a larger reduction in memory for large crop sizes before flattening out for smaller ones. 

\subsection{Comparison with VoxelMorph} \label{SubSec:DiscussionComparisonVoxelMorph}
As a comparison with a very common unsupervised registration network, the registration performance and memory imprint of \emph{Fourier-Net}, \emph{Fourier-Net+} and \emph{4xFourier-Net+} was compared in section~\ref{SubSec:ResultsComparisonVoxelMorph} to \emph{VoxelMorph}. Overall, \emph{4xFourier-Net+} is the only model that is truly more efficient and has a better performance in terms of Dice than \emph{VoxelMorph}, as \emph{Fourier-Net+} is more efficient, but not necessarily better in terms of Dice score, while \emph{Fourier-Net} is far superior in registration performance (as measured by the Dice score), but less efficient in terms of memory consumption.

\subsection{Dense Displacements} \label{SubSec:DiscussionDenseDisplacements}
As a final ablation study, the difference between a band-limited and a dense displacement in \emph{Fourier-Net}, \emph{Fourier-Net+} and \emph{4xFourier-Net+} was tested in section \ref{SubSec:ResultsDenseDisplacementAcc}. The results for the band-limited networks are consistently worse (or in the best case just as good) compared to their dense versions across all acceleration factors for Dice, SSIM and MSE. The band-limiting of the displacement helps with avoiding folding and in most cases decrease inference time, however at the expense of registration performance. Our hypothesis that the advantage of the dense displacement compared to the band-limited displacement disappears for accelerated data does not seem to hold as the dense networks outperform the band-limited ones, though the difference is small in some cases. In the end, the larger dense networks perform better, but also require more memory. Thus, similar to the previous experiments, a balance between performance and memory efficiency has to be found.

\subsection{Comparison on Subsampled Data} \label{SubSec:DiscussionComparisonSubsampling}
In section~\ref{SubSec:ResultsComparisonSubsampling} the registration performance of \emph{Fourier-Net}, \emph{Fourier-Net+} and \emph{4xFourier-Net+} was compared to an unaligned baseline as well as \emph{NiftyReg} and \emph{VoxelMorph} for four different reduction factors. To summarize the results, \emph{Fourier-Net+} is the fastest method for all acceleration levels while \emph{NiftyReg} is far behind all other methods in execution time as it is not machine learning based. \emph{VoxelMorph} performs best in terms of SSIM and MSE for all acceleration factors, however it also has the highest percentage of non-positive Jabobian determinants by a large margin indicating potential folding artifacts. \emph{4xFourier-Net+} performs best in terms of Dice with the background label except for $R=0$ while consistently having the lowest percentage of non-positive Jabobian determinants with a mean value under $0.004\%$ for all acceleration factors. \emph{Fourier-Net+} performs well in terms of Dice (with and without the background label), however it does not manage to surpass the other \emph{Fourier-Net} variants despite having the second lowest percentage of non-positive Jabobian determinants across the acceleration factors. \emph{Fourier-Net} performs best in terms of Dice without the background label for all acceleration level as well as in Dice with the background for $R=0$. \emph{NiftyReg} consistently performs worse than the baseline in terms of Dice (with and without the background) across all acceleration factors while having decent SSIM and MSE values. The performance, in general, decreased for all methods for higher acceleration factors as seen in the Dice metric, however, perhaps counter-intuitively, the SSIM is highest and the MSE the lowest for the $R=10$ baseline with only $R=4$ breaking the trend. This shows once again that image similarity metrics are not completely objective when it comes to evaluating registration performance across different acceleration factors.


\section{Integration into a Motion-Compensated Reconstruction Pipeline} \label{Sec:DiscussionIntegrationMotion-CompensatedReconstructionPipeline}
As a final down-stream task, the usage of \emph{Fourier-Net}, \emph{Fourier-Net+} and \emph{4xFourier-Net+} as part of an motion-compensated reconstruction pipeline was evaluated.

%% remove subsections once most of the text is done
\subsection{Domain Translation} \label{SubSec:DiscussionDomainTranslation}
First, the domain translation between the \emph{ACDC} and \emph{CMRxRecon} datasets was tested for the networks. As seen in section~\ref{SubSec:ResultsDomainTranslation}, the results for all networks are very similar. The mean values of all metrics for \emph{Fourier-Net+} and \emph{4xFourier-Net+} were the same with only a small difference in inference time between the networks. The same is true for the MSE and percentage of non-positive Jabobian determinants of \emph{Fourier-Net}, however, the SSIM is slightly better for the version trained on \emph{ACDC} with a difference of about $0.2 \%$. Thus, overall, no domain gap was observed.

\subsection{Reconstruction Pipeline} \label{SubSec:DiscussionReconstructionPipeline}
Next, a reconstruction pipeline was build and tested using two different methods for simulating motion in an MRI image.

\subsubsection{K-Space Line Swapping}
As expected, the performance for $z=16$ is better than $z=32$ as the latter contains more artifacts. In both cases, performance also decreases for higher acceleration as expected. Overall, the results for $z=32$ are far easier to interpret. \emph{Fourier-Net} performs best for $R=4$ with \emph{4xFourier-Net+} underperforming, while \emph{Fourier-Net+} performs best for $R=8$ and $R=10$. For $z=16$, the results are far less cohesive. \emph{Fourier-Net} performs best in HaarPSI and SSIM for $R=4$ and $R=8$, but underperforms for $R=10$ while \emph{4xFourier-Net+} is best in PSNR and MSR for $R=8$ and performs best across all metrics for $R=10$. \emph{Fourier-Net+} underperforms for $R=4$, but is decent for the other reduction factors. The MSE metrics overall is barely usable as the differences between the images are not captured by the metric (differences in mean values often in the sixth decimal point). However, even the other metrics are very similar for each reduction factor which implies that the reconstruction does not have a large impact on image quality. This is perhaps due to motion artifacts mostly blurring the images and still being too tame. These potential problem were addressed in the next test.

\subsubsection{Simulated Lung Movement}
Simulated Lung Movement...

\section{Limitations and Outlook}
While the registration performance of \emph{Fourier-Net}, \emph{Fourier-Net+} and \emph{4xFourier-Net+} was very good on the \emph{ACDC} dataset, beating traditional algorithms and other neural networks, further comparisons with other more advanced networks such as LAPNet~\cite{LAPNet} on another cardiac dataset would be interesting. While three different reduction factors were used for most of the experiment, even higher acceleration could be an interesting test for the networks adaptability. In general, all network versions were specific to their acceleration. A test for the generalization of the learned properties would be interesting as the networks could be applied to another acceleration as they were trained on. In the best case a network could be trained on all of the data with different reduction factors to hopefully generalize the results for all accelerations. This would make an application to real world problems far easier as a single network could be used for a range of different data.Changes and additions to the network architecture and training of \emph{Fourier-Net}, \emph{Fourier-Net+} and \emph{4xFourier-Net+} might also be interesting to further optimize the performance.\\
A problem with evaluating the reconstruction pipeline are the different networks training performance. As a new network is trained for each reduction factor, the performance might not just be impacted by the acceleration of the image, but also by the networks training. As the latter is non-deterministic in nature it can be hard in some cases to separate whether the network simply underperformed compared to its usual potential or whether the task is truly much more challenging. As an example, \emph{Fourier-Net+} in some cases outperformed its cascaded version \emph{4xFourier-Net+} which is unexpected. In most cases the smaller, more efficient \emph{Fourier-Net+} would show a decrease in performance compared to the larger \emph{Fourier-Net} and \emph{4xFourier-Net+}, however, in some cases due to fluctuation in the training, this assumption would not hold. This further complicates accurately interpreting the results obtained in the different experiments.\\
\emph{Fourier-Net}, \emph{Fourier-Net+} and \emph{4xFourier-Net+} are very versatile networks that can be used for different tasks and data regarding image registration. In the future... 