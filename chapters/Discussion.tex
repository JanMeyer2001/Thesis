%%%%%%%%%%%%%%%%%%%%%%%
%%%%%  Discussion %%%%%
%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Discussion} \label{Ch:Discussion}
Possible implications will be discussed to determine the effectiveness of this new method.

\section{Parameter Tests on the ACDC Dataset} \label{Sec:DiscussionParameterTestsACDC}
First, the results of the parameter tests on the \emph{ACDC} dataset need to be analyzed.

\subsection{Fourier-Net versus Fourier-Net+} \label{SubSec:DiscussionFourier-NetvsFourier-Net+ACDC}

\subsection{Starting Channel Size} \label{SubSec:DiscussionStartingChannelsACDC}

\subsection{Fourier-Transform Crop Size} \label{SubSec:DiscussionFTCropSize}

\subsection{Comparison with VoxelMorph} \label{SubSec:DiscussionComparisonVoxelMorph}


\subsection{Dense Displacements} \label{SubSec:DiscussionDenseDisplacements}
The results for the band-limited networks are consistently worse (or in the best case just as good) compared to their dense versions across all acceleration factors for Dice, SSIM and MSE. The band-limiting of the displacement helps with avoiding folding and in most cases decrease inference time, however at the expense of registration performance. Our hypothesis that the advantage of the dense displacement compared to the band-limited displacement disappears for accelerated data does not seem to hold as the dense networks outperform the band-limited ones, though the difference is small in some cases. In the end, the larger dense networks perform better, but also require more memory. Thus, similar to the previous experiments, a balance between performance and memory efficiency has to be found.

\subsection{Comparison on Subsampled Data} \label{SubSec:DiscussionComparisonSubsampling}
To summarize the results, \emph{Fourier-Net+} is the fastest method for all acceleration levels while \emph{NiftyReg} is far behind all other methods in execution time as it is not machine learning based. \emph{VoxelMorph} performs best in terms of SSIM and MSE for all acceleration factors, however it also has the highest percentage of non-positive Jabobian determinants by a large margin indicating potential folding artifacts. \emph{4xFourier-Net+} performs best in terms of Dice with the background label except for $R=0$ while consistently having the lowest percentage of non-positive Jabobian determinants with a mean value under $0.004\%$ for all acceleration factors. \emph{Fourier-Net+} performs well in terms of Dice (with and without the background label), however it does not manage to surpass the other \emph{Fourier-Net} variants despite having the second lowest percentage of non-positive Jabobian determinants across the acceleration factors. \emph{Fourier-Net} performs best in terms of Dice without the background label for all acceleration level as well as in Dice with the background for $R=0$. \emph{NiftyReg} consistently performs worse than the baseline in terms of Dice (with and without the background) across all acceleration factors while having decent SSIM and MSE values. The performance, in general, decreased for all methods for higher acceleration factors as seen in the Dice metric, however, perhaps counter-intuitively, the SSIM is highest and the MSE the lowest for the $R=10$ baseline with only $R=4$ breaking the trend. This shows once again that image similarity metrics are not completely objective when it comes to evaluating registration performance across different acceleration factors.


\section{Integration into a Motion-Compensated Reconstruction Pipeline} \label{Sec:DiscussionIntegrationMotion-CompensatedReconstructionPipeline}


\subsection{Domain Translation} \label{SubSec:DiscussionDomainTranslation}


\subsection{Reconstruction Pipeline} \label{SubSec:DiscussionReconstructionPipeline}


\section{Limitations and Outlook}
