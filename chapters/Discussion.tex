%%%%%%%%%%%%%%%%%%%%%%%
%%%%%  Discussion %%%%%
%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Discussion} \label{Ch:Discussion}
After presenting the results of the experiments described in section~\ref{Sec:Experiments}, the findings and limitations are discussed in this chapter. First, the ablation studies, parameter tests and registration performance tests conducted on the \emph{ACDC} dataset are discussed before assessing the evaluation of the reconstruction pipeline on the \emph{CMRxRecon} dataset.

\section{Ablation Studies and Parameter Tests} \label{Sec:DiscussionParameterTestsACDC}
For the first tests, different ablation studies and parameter tests were conducted to find the best parameters for \emph{Fourier-Net}, \emph{Fourier-Net+} and \emph{4xFourier-Net+} on the \emph{ACDC} dataset. We will discuss the impact of these tests and its effects on the parameter choices in subsequent experiments.

\subsubsection{Fourier-Net versus Fourier-Net+} \label{SubSubSec:DiscussionFourier-NetvsFourier-Net+ACDC}
In a first comparative study, the performance of \emph{Fourier-Net}, \emph{Fourier-Net+} and \emph{4xFourier-Net+} was compared in section ~\ref{SubSec:ResultsFourier-NetvsFourier-Net+ACDC} together with their respective memory consumption. For the dense displacement variants, the diffeomorphic transform increases the performance slightly for \emph{Fourier-Net} and \emph{4xFourier-Net}, but decreases for \emph{Fourier-Net+}. The times between the baseline and diffeomorphic versions are comparable. The results for the band-limited versions are very similar with \emph{Fourier-Net} and \emph{Fourier-Net+} performing slightly worse  with the diffeomorphism, while \emph{4xFourier-Net} performs better.  These changes are not consistent with the dense displacement versions, however, the band-limited \emph{4xFourier-Net} version might be an outlier, as all of the other models are not affected as much by the diffeomorphic transform. The percentage of non-positive Jabobian determinants decreases for all diffeomorphic variants, which was expected.\\
Overall, the dense displacement versions perform better in terms of Dice (with and without the background label), SSIM and MSE for all models. This is to be expected as the dense displacement versions can use all of the available k-space data for the registration task, while the band-limited versions have only a limited amount of k-space data, directly impacting and limiting their performance. The dense displacement are only slightly better in the SSIM and MSE metrics, however the difference is not quite as large as with the Dice scores. As the differences between the frames is rather small, except for the cardiac region, the weaker registration performance does not impact this metric as much as the Dice score, which is focused on the moving cardiac region.\\
Only in terms of the percentage of non-positive Jabobian determinants does the band-limited displacement actually perform better as the band-limiting leads to a smoother deformation. However, the difference is still very small, especially for the diffeomorhpic versions, and it could be argued that a better registration performance at the cost of some image folding is an acceptable trade-off. \\
As opposed to our intuition, the dense displacements variants are faster in terms of inference speeds despite having the larger encoder, however all of the model are very fast (7~ms up to 33.5~ms). Lastly, the memory consumption needs to be addressed. The dense displacment variants have a larger encoder as discussed before and thus have more parameters which is very noticeable for the otherwise very efficient \emph{Fourier-Net+} and \emph{4xFourier-Net} (about 5 times more). The number of Mult-Adds and the amount of total memory are more than doubled (almost tripled for \emph{4xFourier-Net}) for the dense displacement versions compared to those with a band-limited displacement across all models. This shows that a larger network produces better results, however for certain applications where efficiency is needed a smaller, but slightly less performant, network might be more beneficial.\\
To summarize, \emph{Fourier-Net} performs best for the band-limited displacement, while \emph{4xFourier-Net+} works better with a dense displacement. While the dense displacements overall provide the better performance, the memory cost is enormous. Utilizing a diffeomorphic transform does not generally lead to a better performance.

\subsubsection{Starting Channel Size} \label{SubSubSec:DiscussionStartingChannelsACDC}
One of the most important parameters for the networks is the channel size. A larger channel size means more features, but also a larger network. The results from section~\ref{SubSec:ResultsStartingChannelsACDC} show that memory efficiency and registration performance for \emph{Fourier-Net+} and \emph{4xFourier-Net+} cannot be optimized at the same time. There is a clear trade-off between the two. For both \emph{Fourier-Net+} and \emph{4xFourier-Net+} a clear increase in performance with larger channel sizes can be observed as more features are utilized. The percentage of non-positive Jabobian determinants also decreases as the registration performance increases, likely due to it having more features enabling the prediction of better displacements. The inference time is not impacted by channel size. The memory however increases exponentially when doubling the channel sizes as all layers are effected, not just the starting one as the name might suggest. Thus, the number of parameters drastically increases with starting size leading to an increase in Mult-Add and thus overall memory. \\
To summarize, as the channel sizes increase, making the network larger, the performance also increases. While this effect is quite large at the beginning, it plateaus rather quickly. This trade-off and the diminishing returns imply that there is a sweet spot where the network is still efficient while maintaining a good performance. The starting channel size 16 was thus chosen for the following experiments.

\subsubsection{Fourier-Transform Crop Size} \label{SubSubSec:DiscussionFTCropSize}
The FT crop is specific to \emph{Fourier-Net+} and \emph{4xFourier-Net+}, however, the size of the crop has a mayor impact on the input images as a smaller crop leads to more compressed images, but also better memory usage. Similarly to channel size before, the results in section~\ref{SubSec:ResultsFTCropSize} indicate that there is no sweet-spot to be found that maximizes both memory efficiency and registration performance. The latter decreases drastically with a smaller crop size. This is to be expected as the smaller FT drop compresses the images more, making an accurate registration more difficult. Another factor that negatively effects images for smaller crop sizes are potential over-folding artifacts due to the properties of the k-space. As a consequence, a reduction in crop size does not only lead to a smaller spatial resolution, but also a reduction of the FOV. This can cause the image to fold back into itself upon applying the iFFT leading to over-folding artifacts which can also severely hinder registration. \\
Interestingly, the percentage of non-positive Jacobian determinants actually decreases for smaller crop sizes, perhaps because the displacements on the compressed images are not as extreme and thus more smooth. Inference time also seems to decrease slightly with a smaller crop, although the time measurements are not quite consistent. The number of parameters does not change for different crop sizes as the networks themselves do not change, however the number of Mult-Adds and the total memory still change with the image size. Both decrease with a larger crop size as the image gets smaller. This effect is again not linear as a reduction in image size yields a larger reduction in memory for large crop sizes before flattening out for smaller ones. Overall, there is, again, a trade-off between memory efficiency and registration performance similar to the channel size.

\subsubsection{Comparison with VoxelMorph} \label{SubSubSec:DiscussionComparisonVoxelMorph}
As a comparison with a very common unsupervised registration network, the registration performance and memory imprint of \emph{Fourier-Net}, \emph{Fourier-Net+} and \emph{4xFourier-Net+} was compared in section~\ref{SubSec:ResultsComparisonVoxelMorph} to \emph{VoxelMorph}. \emph{Fourier-Net} has the best registration performance as indicated by the Dice score, followed by \emph{4xFourier-Net+} as expected. \emph{VoxelMorph}, however, does perform best in terms of SSIM and MSE followed by \emph{Fourier-Net}, so it seems that the dense network aligns the overall image well, but struggles to compensate the strong changes in the cardiac region between frames. \emph{VoxelMorph} has the highest the percentage of non-positive Jabobian determinants compared to the other models. This is perhaps caused by the dense displacement which causes a better overall alignment (as indicated by the good SSIM and MSE values) at the cost of some minor folding occurring. While \emph{VoxelMorph} has the least amount of parameters and Mult-Adds it needs almost 40~MB of memory, perhaps due to the dense displacment. \emph{Fourier-Net} is the largest model with a total memory of 90~MB. \\
Overall, \emph{4xFourier-Net+} is the only model that is truly more efficient and has a better performance in terms of Dice than \emph{VoxelMorph}, as \emph{Fourier-Net+} is more efficient, but not necessarily better in terms of Dice score, while \emph{Fourier-Net} is far superior in registration performance (as measured by the Dice score), but less efficient in terms of memory consumption.

\subsubsection{Dense Displacements} \label{SubSubSec:DiscussionDenseDisplacements}
As a final ablation study, the difference between a band-limited and a dense displacement in \emph{Fourier-Net}, \emph{Fourier-Net+} and \emph{4xFourier-Net+} was tested in section \ref{SubSec:ResultsDenseDisplacementAcc}. The results for the band-limited networks are consistently worse (or in the best case just as good) compared to their dense versions across all acceleration factors for Dice, SSIM and MSE. The band-limiting of the displacement helps with avoiding folding and in most cases decrease inference time, however at the expense of registration performance. The hypothesis that the advantage of the dense displacement compared to the band-limited displacement disappears for accelerated data does not seem to hold as the dense networks outperform the band-limited ones, though the difference is small in some cases. In the end, the larger dense networks perform better, but also require more memory. Thus, similar to the previous experiments, a balance between performance and memory efficiency has to be found.

\section{Registration Performance on Subsampled Data} \label{SubSubSec:DiscussionComparisonSubsampling}
In section~\ref{SubSec:ResultsComparisonSubsampling} the registration performance of \emph{Fourier-Net}, \emph{Fourier-Net+} and \emph{4xFourier-Net+} was compared to an unaligned baseline as well as \emph{NiftyReg} and \emph{VoxelMorph} for four different reduction factors. To summarize the results, \emph{Fourier-Net+} is the fastest method for all acceleration levels while \emph{NiftyReg} is far behind all other methods in execution time as it is not a deep learning based method. \emph{VoxelMorph} performs best in terms of SSIM and MSE for all acceleration factors, however it also has the highest percentage of non-positive Jabobian determinants indicating potential folding artifacts. \emph{4xFourier-Net+} performs best in terms of Dice with the background label except for $R=0$ while consistently having the lowest percentage of non-positive Jabobian determinants with a mean value under $0.004\%$ for all acceleration factors. \emph{Fourier-Net+} performs well in terms of Dice (with and without the background label), however it does not manage to surpass the other \emph{Fourier-Net} variants despite having the second lowest percentage of non-positive Jabobian determinants across the acceleration factors. \emph{Fourier-Net} performs best in terms of Dice without the background label for all acceleration level as well as in Dice with the background for $R=0$. \emph{NiftyReg} consistently performs worse than the baseline in terms of Dice (with and without the background) across all acceleration factors while having decent SSIM and MSE values. The performance, in general, decreased for all methods for higher acceleration factors as seen in the Dice metric, however, perhaps counter-intuitively, the SSIM is highest and the MSE the lowest for the $R=10$ baseline with only $R=4$ breaking the trend. This shows once again that image similarity metrics are not completely objective when it comes to evaluating registration performance across different acceleration factors.

\subsubsection{Cardiac Labels}
With the examination of the Dice scores it becomes apparent that these vary widely for each cardiac label. The overall performance of the methods is best for the right ventricle and worst for the myocardium which seems to be an underlying principle of the data as the unaligned baseline exhibits the same behavior. Overall, \emph{NiftyReg} is not heavily affected by the artifacts present in the subsampled data, but is also not able to perform better than the other methods consistently. \emph{VoxelMorph} is able to outperform the baseline, \emph{NiftyReg} and even \emph{Fourier-Net+} on one occasion, but is severely hampered by the artifacts caused by the subsampling of the k-space thus limiting its usability for accelerated MRI applications. While \emph{Fourier-Net} is effected by the subsampling the effect is far less severe compared to \emph{VoxelMorph}, and \emph{Fourier-Net} reaches a far better performance, especially for the challenging myocardium. The same is true for \emph{Fourier-Net+}, which performs better on the right ventricle, and \emph{4xFourier-Net+}, which performs better for the left ventricle. 

\subsubsection{Qualitative Results}
Lastly, the visual examination needs to be discussed. \emph{Fourier-Net+} and \emph{4xFourier-Net+} overall have very localized displacements, which centered on the cardiac region. This leads to very smooth warped segmentations even for highly accelerated images. \emph{Fourier-Net}, \emph{VoxelMorph} and \emph{NiftyReg} on the contrary have more diffuse displacement leading to cardiac labels mixing in some cases. Thus those networks have learned a less localized transformation, which becomes more pronounced for higher reduction factors. While \emph{Fourier-Net+} and \emph{4xFourier-Net+} also experience this effect to some extend, they are far more robust than the other methods. In the worst case, \emph{VoxelMorph} and \emph{NiftyReg} try to align rippling and ringing artifacts in the images that differ between moving and fixed images. This is of course not desirable as the movement between the frames happens mostly in the cardiac region with the rest of the frames remaining mostly stationary. It should be noted however that a smoother displacement does not necessarily lead to a better Dice score. 


\section{Integration into a Motion-Compensated Reconstruction Pipeline} \label{Sec:DiscussionIntegrationMotion-CompensatedReconstructionPipeline}
As a final down-stream task, the usage of \emph{Fourier-Net}, \emph{Fourier-Net+} and \emph{4xFourier-Net+} as part of an motion-compensated reconstruction pipeline was evaluated.

\subsubsection{Domain Translation} \label{SubSec:DiscussionDomainTranslation}
First, the domain translation between the \emph{ACDC} and \emph{CMRxRecon} datasets was tested for the networks. As seen in section~\ref{SubSec:ResultsDomainTranslation}, the results for all networks are very similar. The mean values of all metrics for \emph{Fourier-Net+} and \emph{4xFourier-Net+} were the same with only a small difference in inference time between the networks. The same is true for the MSE and percentage of non-positive Jabobian determinants of \emph{Fourier-Net}, however, the SSIM is slightly better for the version trained on \emph{ACDC} with a difference of about $0.2 \%$. This might be due to the larger \emph{ACDC} training dataset or simply statistical fluctuation due to the random start weight which can lead to slightly better results in some cases. However, overall, no domain gap was observed.

%\subsection{Reconstruction Pipeline} \label{SubSec:DiscussionReconstructionPipeline}
%Next, a reconstruction pipeline was build and tested using two different methods for simulating motion in an MRI image.

\subsubsection{K-Space Line Swapping}
Next, a reconstruction pipeline was build and tested using two different methods for simulating motion in an MRI image. The first was motion/mistriggering simulated by swapping lines in the k-space. As expected, the performance for $z=16$ is better than $z=32$ as the latter contains more artifacts. In both cases, performance also decreases for higher acceleration as expected. Overall, the results for $z=32$ are far easier to interpret. \emph{Fourier-Net} performs best for $R=4$ with \emph{4xFourier-Net+} underperforming, while \emph{Fourier-Net+} performs best for $R=8$ and $R=10$. For $z=16$, the results are far less cohesive. \emph{Fourier-Net} performs best in HaarPSI and SSIM for $R=4$ and $R=8$, but underperforms for $R=10$ while \emph{4xFourier-Net+} is best in PSNR and MSR for $R=8$ and performs best across all metrics for $R=10$. \emph{Fourier-Net+} underperforms for $R=4$, but is decent for the other reduction factors. The MSE metrics overall is barely usable as the differences between the images are not captured by the metric (differences in mean values often in the sixth decimal point). However, even the other metrics are very similar for each reduction factor which implies that the reconstruction does not have a large impact on image quality. This is perhaps due to motion artifacts mostly blurring the images and still being too tame. Since the k-space line swapping occurs in the high-frequencies, the first idea was to register them in the band-limited space as it could be corruption agnostic (only low frequencies). But the evaluation is not easy so, as a second experiment, we choose another approach for simulating motion. These potential problem were addressed in the next test as extra frames with simulated lung movement were used.

\subsubsection{Simulated Lung Movement}
For $R=4$, \emph{Fourier-Net} performs best followed by \emph{Fourier-Net+} and \emph{4xFourier-Net+} while for $R=8$ and $R=10$ \emph{Fourier-Net+} overtakes \emph{Fourier-Net}. It is surprising that \emph{Fourier-Net+} outperforms \emph{4xFourier-Net+} in this experiment as the latter had previously shown better performance at the expense of memory efficiency. \emph{VoxelMorph} is the weakest method though still quite a lot better than the baseline without any motion-compensation. Interestingly, the metrics, while being very much affected by the increased subsampling going $R=8$ to $R=4$, do not decrease quite as much going from $R=8$ to $R=10$. This is probably due to the reduction factor only increasing by 2 compared to the 4 for the step before. 

\subsubsection{Qualitative Results}
For $R=4$, \emph{VoxelMorph} has a very blurred cardiac region and a small tear is visible. Despite the superior performance in terms of metrics, there are still some artifacts visible in the error map for \emph{Fourier-Net} stemming from the subsampling. \emph{Fourier-Net+} has strong blurring in the left part of the image with \emph{4xFourier-Net+} having similar artifacts, though not quite as much. For $R=8$, the visual look improves despite the higher acceleration which is quite surprising. However, these examples often do not exactly represent the entirety of the data as the mean values for the metrics do degrade as seen before. For $R=10$, \emph{Fourier-Net+} looks similar to $R=8$ being mostly free of artifacts besides for blurring from the subsampling that the reconstruction could not fully remove, while \emph{VoxelMorph} contains artifacts similar to $R=4$ except for the tearing in the cardiac region. \emph{Fourier-Net} has warping the left part of the image with some of the pixel values getting distorted and \emph{4xFourier-Net+}, similar to \emph{Fourier-Net}, has large blurring artifacts in the cardiac region.

\section{Efficiency and Performance Trade-offs} \label{Sec:EfficiencyPerformanceTrade-offs}
A reoccurring phenomenon of a trade-off between memory efficiency and performance. In both the starting channel results of section~\ref{SubSec:ResultsStartingChannelsACDC} and the FT crop size results in section~\ref{SubSec:ResultsFTCropSize} this trend is visible. Even further, in the comparison on subsampled data \emph{Fourier-Net} and \emph{4xFourier-Net+} often showed the best results in section~\ref{SubSec:ResultsComparisonSubsampling}. All of these points support the idea of a trade-off as the most efficient network variant, \emph{Fourier-Net+}, often lacks behind it predecessor and its cascaded version. This makes sense as it contains an image crop that reduces the information the network receives as input. The whole reasoning behind \emph{4xFourier-Net+} is to recover some of the lost performance by cascading multiple instances of \emph{Fourier-Net+} with independent weights similar to a random forest or boosting approach.\\
This, however, is only possible because \emph{Fourier-Net+} is so much more efficient than e.g. \emph{Fourier-Net} and \emph{VoxelMorph}. In the results from section~\ref{SubSec:ResultsComparisonVoxelMorph}, \emph{Fourier-Net+} only needs about $5 \%, 27 \%$ and $12 \%$ of the memory that \emph{Fourier-Net}, \emph{4xFourier-Net+} and \emph{VoxelMorph} need. \emph{Fourier-Net+} is extremely efficient which can be imperative for certain applications like small portable devices. While this is definitely not the case for big MRI scanners, this aspect of \emph{Fourier-Net+} should not be overlooked. Even a 4x cascaded Version in \emph{4xFourier-Net+} only needs about $19 \%$ of the memory that \emph{Fourier-Net} requires and still less than half compared to \emph{VoxelMorph}. Despite this, it frequently outperforms the latter in e.g. registration performance and competes with \emph{Fourier-Net} on many occasions.\\
It should also be noted that \emph{Fourier-Net} does not always perform best despite its large memory footprint. In some instances, like the motion-compensated reconstruction, the added registration performance does not seem to be as much of an factors (especially for higher accelerations) and the usefulness of the memory efficiency that \emph{Fourier-Net} provides becomes even more pronounced.

\section{Limitations and Outlook} \label{Sec:LimitationsOutlook}
Now to the limitations of the experiments and results. There are multiple potential points for improvements of both the performance as well as the experimental setup. Lastly, future work is discussed in the outlook.

\subsubsection{Extending the Scope of the Experiments and Network Training} \label{SubSubSec:ExtendingScopeExperimentsNetworkTraining}
While the registration performance of \emph{Fourier-Net}, \emph{Fourier-Net+} and \emph{4xFourier-Net+} was very good on the \emph{ACDC} dataset, beating traditional algorithms and other neural networks, further comparisons with other more advanced networks such as LAPNet~\cite{LAPNet} on another cardiac dataset would be interesting. While three different subsampling factors were used for most of the experiment, even higher accelerations could be an interesting test for the networks adaptability to even more severe aliasing artifacts. In general, all network versions were specific to their acceleration. A test for the generalization of the learned properties would be interesting as the networks could be applied to another acceleration as they were trained on. In the best case a network could be trained on all of the data with different reduction factors to hopefully generalize the results for all accelerations. This would make an application to real world problems far easier as a single network could be used for a range of different data. Changes and additions to the network architecture and training of \emph{Fourier-Net}, \emph{Fourier-Net+} and \emph{4xFourier-Net+} might also be interesting to further optimize the performance. However, a first step should be to extend the network and experiments to 3D as all previous experiments were conducted on only 2D slices although MRI data is naturally acquired as 3D volumes and this should ideally be reflected in the registration networks. This would not just improve the ease of use as the data needs less processing for usage, but it might also highlight the efficiency of \emph{Fourier-Net}, \emph{Fourier-Net+} and \emph{4xFourier-Net+} as another spatial dimension makes the networks even larger leading to a bigger advantage for efficient methods.

\subsubsection{Challenges of Evaluation} \label{SubSubSec:ChallengesEvaluation}
A problem with evaluating the reconstruction pipeline are the different networks training performance. As a new network is trained for each reduction factor, the performance might not just be impacted by the acceleration of the image, but also by the networks training. As the latter is non-deterministic in nature it can be hard in some cases to separate whether the network simply underperformed compared to its usual potential or whether the task is truly much more challenging. As an example, \emph{Fourier-Net+} in some cases outperformed its cascaded version \emph{4xFourier-Net+} which is unexpected. In most cases the smaller, more efficient \emph{Fourier-Net+} would show a decrease in performance compared to the larger \emph{Fourier-Net} and \emph{4xFourier-Net+}, however, in some cases due to fluctuation in the training, this assumption would not hold. This further complicates accurately interpreting the results obtained in the different experiments on top on evaluation limitations inherent to the reconstruction pipeline due to the simulated motion. The k-space line swapping was difficult to evaluate as it is more of a motion-correction problem for a single image, rather than motion-compensation for multiple images. The latter is more suitable for the usage of image registration and was explored with the simulated non-linear lung motion. This however is also a very artificial tests as the data is very synthetic and not quite realistic for actual lung movement. In the future, this test should repeated with real lung motion data preferably in 3D to be as close to the real-world application as possible.
